{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd022a63b945ad88ad6aa60a7f3f570c70abf6faa8a03284077614716ef20649993",
   "display_name": "Python 3.7.10 64-bit ('uni': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# RAKE \n",
    "short for Rapid Automatic Keyword Extraction algorithm, is a domain independent keyword extraction algorithm which tries to determine key phrases in a body of text by analyzing the frequency of word appearance and its co-occurance with other words in the text.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: python-rake in c:\\anaconda\\envs\\uni\\lib\\site-packages (1.5.0)\n",
      "Collecting rake-nltk\n",
      "  Downloading rake_nltk-1.0.4.tar.gz (7.6 kB)\n",
      "Requirement already satisfied: nltk in c:\\anaconda\\envs\\uni\\lib\\site-packages (from rake-nltk) (3.6.2)\n",
      "Requirement already satisfied: click in c:\\anaconda\\envs\\uni\\lib\\site-packages (from nltk->rake-nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\anaconda\\envs\\uni\\lib\\site-packages (from nltk->rake-nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\envs\\uni\\lib\\site-packages (from nltk->rake-nltk) (4.60.0)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\envs\\uni\\lib\\site-packages (from nltk->rake-nltk) (1.0.1)\n",
      "Building wheels for collected packages: rake-nltk\n",
      "  Building wheel for rake-nltk (setup.py): started\n",
      "  Building wheel for rake-nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for rake-nltk: filename=rake_nltk-1.0.4-py2.py3-none-any.whl size=7829 sha256=276ee8781a80b235f3ff85b7decb1bcad2502fb9f3d112a1a107e3ddc6d204ac\n",
      "  Stored in directory: c:\\users\\home\\appdata\\local\\pip\\cache\\wheels\\7c\\d9\\8a\\b8a9244fa89a07f288f9fe006aafc79d93fceb58496c29b606\n",
      "Successfully built rake-nltk\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install python-rake\r\n",
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\home\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "post = \"Getting back to work made a difference. After 10 days of nothing but the business of moving and all of its seemingly obligatory messy emotions, it was nice to think of nothing but my patients. I worked Wednesday through Friday, and even with a couple of long days in there, it was a relief to be away from home. It was a relief to be away from unpacking, and contemplating, and deciding. It was a pleasure to think about somebody other than myself for 3 days. I needed that. Those 3 days away, combined with a long run/walk/dip into Lake Superior with Jet yesterday, gave me the energy to unpack nearly my entire basement today. I ve still got a lot to do, but things are starting to take shape. My bedroom is almost completely put together. My bathroom and kitchen are done. I ve still got boxes in the living room, dining room and the other 2 bedrooms, but I m getting there. Tomorrow I m heading south to Mayo Clinic for a ketamine infusion. Im pleased its not an urgent need at this time, just a regular maintenance dose. Returning to work, getting some exercise, and progressing with my unpacking have each helped stabilize my mood. Im  no longer daily wiping tears from my eyes. In fact, I haven t cried for several days. That, in and of itself, is quite a feat! I m taking my time with unpacking. I m doing my best to remain patient. Taking the next right action and maintaining my attitude of gratitude are my focus now. Its still hard, but its not impossible. Settling into my new home, new routine, and new city will take time. I m keeping that fact forefront in my mind. I can do this. But I cant do it all today, nor do I have to. Patiently, Ill get it done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['regular maintenance dose',\n",
       " 'next right action',\n",
       " 'entire basement today',\n",
       " 'still got boxes',\n",
       " '3 days away',\n",
       " 'still got',\n",
       " '3 days',\n",
       " 'still hard',\n",
       " 'several days',\n",
       " 'long days',\n",
       " '10 days',\n",
       " 'worked wednesday',\n",
       " 'work made',\n",
       " 'urgent need',\n",
       " 'unpack nearly',\n",
       " 'take time',\n",
       " 'take shape',\n",
       " 'remain patient',\n",
       " 'new routine',\n",
       " 'new home',\n",
       " 'new city',\n",
       " 'mayo clinic',\n",
       " 'long run',\n",
       " 'living room',\n",
       " 'lake superior',\n",
       " 'ketamine infusion',\n",
       " 'jet yesterday',\n",
       " 'im pleased',\n",
       " 'ill get',\n",
       " 'helped stabilize',\n",
       " 'heading south',\n",
       " 'getting back',\n",
       " 'fact forefront',\n",
       " 'dining room',\n",
       " '2 bedrooms']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "r = Rake(min_length=2, max_length=3) # Uses stopwords for english from NLTK, and all puntuation characters.\n",
    "\n",
    "r.extract_keywords_from_text(post)\n",
    "\n",
    "r.get_ranked_phrases() # To get keyword phrases ranked highest to lowest."
   ]
  },
  {
   "source": [
    "# Spacy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10 days, Wednesday through Friday, a couple of long days, 3 days, Those 3 days, Lake Superior, yesterday, today, 2, Mayo Clinic, daily, several days, today, Ill)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(post)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "work\na difference\n10 days\nnothing\nthe business\nits seemingly obligatory messy emotions\nit\nnothing\nmy patients\nI\nFriday\na couple\nlong days\nit\na relief\nhome\nIt\na relief\nunpacking\nIt\na pleasure\nsomebody\nmyself\n3 days\nI\na long run/walk/dip\nLake Superior\nJet\nme\nthe energy\nnearly my entire basement\nI\na lot\nthings\nshape\nMy bedroom\nMy bathroom\nkitchen\nI\nboxes\nthe living room\ndining room\nthe other 2 bedrooms\nI\nI\nMayo Clinic\na ketamine infusion\nI\nits not an urgent need\nthis time\nwork\nsome exercise\nmy unpacking\nmy mood\nI\ntears\nmy eyes\nfact\nI\nt\nseveral days\nitself\nquite a feat\nI\nmy time\nunpacking\nI\nthe next right action\nmy attitude\ngratitude\nmy focus\nits\nmy new home\nnew routine\nnew city\ntime\nI\nthat fact\nmy mind\nI\nI\nit\nI\nIll\nit\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Verbs: ['get', 'make', 'move', 'think', 'work', 'be', 'be', 'be', 'contemplate', 'decide', 'think', 'need', 'combine', 'give', 'unpack', 'get', 'do', 'start', 'take', 'put', 'do', 'get', 'get', 'head', 'm', 'return', 'get', 'progress', 'help', 'stabilize', 'wipe', 'haven', 'cry', 'take', 'do', 'remain', 'take', 'maintain', 'settle', 'take', 'keep', 'do', 'do', 'have', 'get', 'do']\n"
     ]
    }
   ],
   "source": [
    "# Analyze syntax\n",
    "\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n"
   ]
  }
 ]
}